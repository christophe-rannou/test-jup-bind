{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Time Series with Prescience\n",
    "\n",
    "The best way to understand how to make prediction on timeseries in `Prescience` is probably to do it with an example. For that purpose we are going to use a time serie that traces the evolution in number of bytes of a Ceph cluster usage.\n",
    "\n",
    "The source is already uploaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `source` object\n",
    "\n",
    "We uploaded the raw data from a time serie backend (Warp10) and started a `parse task`. This task includes some pre-analysis on the raw data for later processing and some type resolution.\n",
    "\n",
    "The `source` object is almost like your original data, except that it holds some metadata inside that have been computed during the parse tasks. We wont describe all the metadata here but this is several statistics like :\n",
    "* The standard deviation for each column\n",
    "* The type of data contained in the column (integer, boolean, text, etc...)\n",
    "* If the column can contains `null` values\n",
    "* etc...\n",
    "\n",
    "Let's retrieve the existing sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prescience_client import prescience\n",
    "# Display the list of all sources in your prescience project\n",
    "prescience.sources().show('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get back this source to explore it and get a brief summary of what informations were extracted during the `parse task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = prescience.source('ceph-usage-40w-hourly')\n",
    "source.schema().show('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even plot the source object to visualize the raw timeserie. To do so we need to indicate the name of the column we want to use as abscisse `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.pyplot.rcParams[\"figure.figsize\"] = (20, 3)\n",
    "source.plot(x='time-column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset object\n",
    "\n",
    "The `dataset` object contains the same data than in your `source` except that this data has been transformed so that it can be understandable by machine learning algorithms.\n",
    "\n",
    "The rules of transformation won't be described here but all you have to know is that previously computed statistics are used to choose the good transformation strategy.\n",
    "\n",
    "In our case if we plot the dataset we will see that it looks exactly the same as the source, except that all axis have been standardized (i.e values have been rescaled and bound with 0 as the mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 'dataset-ceph-usage-40w-hourly'\n",
    "prescience.plot_dataset(dataset_id, plot_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataset` object is created from a `source` with a `preprocess task`. Another things to note is that the preprocess task is responsible for creating the `folds` that we previously talk about on `Problem Definition` part.\n",
    "\n",
    "You wan easily see created `folds` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_number in range(3):\n",
    "    prescience.plot_dataset(dataset_id, fold_number=fold_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each fold is composed of 2 parts :\n",
    "* A train part which is used to train machine learning algorithms\n",
    "* A test part which is used to evalute the relevance of a model\n",
    "\n",
    "It is a standard process in machine learning in order to evaluate relevancy of machine learning algorithms on data that they have never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model object\n",
    "\n",
    "The `model` object is created from a `dataset` with a `train task` however a train task needs to be launched on a specific machine learning algorithm with defined parameters. That's why there is an intermediate task which is called the `optimization task`.\n",
    "\n",
    "The aim of an optimization task is to use the previously created folds of our dataset to train a lot of machine learning algorithms with different hyperparameters, evaluate them and find the best.\n",
    "\n",
    "All results of evaluations are stored in prescience into objects called `evaluations results`. You can request the visualisation of previously computed evaluation by doing so :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = prescience.get_evaluation_results(\n",
    "    dataset_id,\n",
    "    # Only display results for the wanted horizon\n",
    "    forecasting_horizon_steps=24,\n",
    "    # Sort all the results by the selected scoring metric\n",
    "    sort_column=f'costs.mse'\n",
    ")\n",
    "evaluation_results.show('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row of the table is the best model and configuration find. If we compare this configuration with the configuration of the model deployed we will see that they are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the config from the best evaluation results\n",
    "config_eval = evaluation_results.content[0].config()\n",
    "\n",
    "import json\n",
    "print(json.dumps(config_eval.kwargs(), indent=4))\n",
    "\n",
    "config_eval.show('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play around with the model\n",
    "\n",
    "We previously trained a model automatically tuned by prescience. It's forecast horizon was set to 24 (the base serie being sampled with an interval of 1 hour) to predict a day forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the list of all models associated to this source\n",
    "source.tree().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the created model on prescience\n",
    "model_id = 'ceph-usage-40w-hourly-model-24hori'\n",
    "model = prescience.model(model_id)\n",
    "\n",
    "# Show the config from the model\n",
    "config_train = model.config()\n",
    "print(json.dumps(config_train.kwargs(), indent=4))\n",
    "config_train.show('html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing predictions results\n",
    "Ploting the predicted result of a model is one of the best way to estimate its relevancy. We are going to choose some arbitrary points in our original data and compare the theorical serie with the predicted one from newly deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN_TIMESTAMP = 1560733200000000\n",
    "\n",
    "# Generate the input payload that will be send to the model for making prediction (it use the initial data to create it)\n",
    "payload_dict = prescience.generate_payload_dict_for_model(model_id, from_data=STEP_TO_PREDICT)\n",
    "\n",
    "# Print this payload :\n",
    "import json\n",
    "print(json.dumps(payload_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask for a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction of the model\n",
    "result_dataframe = model.get_dataframe_for_plot_result(payload_dict)\n",
    "\n",
    "# Plot the prediction of the model\n",
    "matplotlib.pyplot.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "result_dataframe.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask for a rolling prediction\n",
    "We can go a bit further and ask the model to predict even further in the past, the prediction result is used as input for the next forecast. \n",
    "\n",
    "Rolling forecasts tend to be less and less accurate. Usually either the result converges to a fixed value or diverges abruptly.\n",
    "\n",
    "Let's see how this model handles the rolling prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction of the model with a 'rolling' strategy\n",
    "result_dataframe = model.get_dataframe_for_plot_result(payload_dict, rolling_steps=2)\n",
    "\n",
    "# Plot the prediction of the model\n",
    "matplotlib.pyplot.rcParams[\"figure.figsize\"] = (20, 4)\n",
    "result_dataframe.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it seems that the deployed model unsterstood the trend and the seasonality of the underlying time-series. It is a first step, however predictions can be improved. We are going to see what is really happening under the hood and try to improve that prediction.\n",
    "\n",
    "What would happen if we went even further ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction of the model with a 'rolling' strategy\n",
    "result_dataframe = model.get_dataframe_for_plot_result(payload_dict, rolling_steps=6)\n",
    "\n",
    "# Plot the prediction of the model\n",
    "matplotlib.pyplot.rcParams[\"figure.figsize\"] = (20, 4)\n",
    "result_dataframe.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction seems to maintain the seasonality with a lower variance and with an increasing trend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
